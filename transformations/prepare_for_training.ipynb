{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import date\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.transforms import *\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "glueContext = GlueContext(SparkContext.getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET = \"aml-project-storage\"\n",
    "DATABASE = \"historical_data\"\n",
    "TABLE_NAME = \"original\"\n",
    "\n",
    "FOLDER = str(date.today()).replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "df = glueContext.create_dynamic_frame.from_catalog(\n",
    "    database=DATABASE, table_name=TABLE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop and rename columns\n",
    "transactions = (\n",
    "    df.drop_fields([\"step\", \"nameorig\", \"isflaggedfraud\"])\n",
    "    .rename_field(\"oldbalanceorg\", \"balance_source_old\")\n",
    "    .rename_field(\"newbalanceorig\", \"balance_source_new\")\n",
    "    .rename_field(\"oldbalancedest\", \"balance_dest_old\")\n",
    "    .rename_field(\"newbalancedest\", \"balance_dest_new\")\n",
    "    .rename_field(\"isfraud\", \"is_fraud\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode transaction types\n",
    "def encode_type(record):\n",
    "    if record.type == \"CASH_IN\":\n",
    "        record.is_cash_in = 1\n",
    "\n",
    "    elif record.type == \"CASH_OUT\":\n",
    "        record.is_cash_out = 1\n",
    "\n",
    "    elif record.type == \"DEBIT\":\n",
    "        record.is_cash_debit = 1\n",
    "\n",
    "    elif record.type == \"PAYMENT\":\n",
    "        record.is_payment = 1\n",
    "\n",
    "    else:\n",
    "        record.is_transfer = 1\n",
    "    return record\n",
    "\n",
    "\n",
    "transactions = transactions.map(encode_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = transactions.toDF()\n",
    "# Fill NA/Null values\n",
    "transactions_df = transactions_df.na.fill(0)\n",
    "\n",
    "# Encode destination\n",
    "encode_merchant = udf(lambda x: 1 if x[0] == \"M\" else 0, IntegerType())\n",
    "transactions_df = transactions_df.withColumn(\n",
    "    \"is_merchant_dest\", encode_merchant(transactions_df[\"namedest\"])\n",
    ")\n",
    "\n",
    "# Create percentage_amount_source column\n",
    "calculate_balance_percentage = udf(\n",
    "    lambda amount, old_balance: amount / old_balance if old_balance != 0 else 0\n",
    ")\n",
    "transactions_df = transactions_df.withColumn(\n",
    "    \"percentage_amount_source\",\n",
    "    calculate_balance_percentage(\n",
    "        transactions_df[\"amount\"], transactions_df[\"balance_source_old\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "transactions_df = transactions_df.drop(\"namedest\", \"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-order columns - target must be first for XGBoost training\n",
    "columns = transactions_df.columns\n",
    "columns = sorted(columns)\n",
    "columns.remove(\"is_fraud\")\n",
    "transactions_df = transactions_df.select(\"is_fraud\", *columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "training_df, test_df = transactions_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the files for training and testing the model\n",
    "training_df.write.mode(\"overwrite\").csv(f\"s3a://{S3_BUCKET}/train/{FOLDER}/\")\n",
    "test_df.write.mode(\"overwrite\").csv(f\"s3a://{S3_BUCKET}/test/{FOLDER}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
